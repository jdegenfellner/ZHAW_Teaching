@article{Wasserstein2019,
    author = {Ronald L. Wasserstein and Allen L. Schirm and Nicole A. Lazar},
    title = {Moving to a World Beyond “p \textless{} 0.05”},
    journal = {The American Statistician},
    volume = {73},
    number = {sup1},
    pages = {1--19},
    year = {2019},
    doi = {10.1080/00031305.2019.1583913}
}

@article{Goodman2008,
    author = {Steven Goodman},
    title = {A Dirty Dozen: Twelve P-Value Misconceptions},
    journal = {Seminars in Hematology},
    volume = {45},
    number = {3},
    pages = {135--140},
    year = {2008},
    note = {Interpretation of Quantitative Research},
    issn = {0037-1963},
    doi = {https://doi.org/10.1053/j.seminhematol.2008.04.003},
    url = {https://www.sciencedirect.com/science/article/pii/S0037196308000620},
    abstract = {The P value is a measure of statistical evidence that appears in virtually all medical research papers. Its interpretation is made extraordinarily difficult because it is not part of any formal system of statistical inference. As a result, the P value's inferential meaning is widely and often wildly misconstrued, a fact that has been pointed out in innumerable papers and books appearing since at least the 1940s. This commentary reviews a dozen of these common misinterpretations and explains why each is wrong. It also reviews the possible consequences of these improper understandings or representations of its meaning. Finally, it contrasts the P value with its Bayesian counterpart, the Bayes' factor, which has virtually all of the desirable properties of an evidential measure that the P value lacks, most notably interpretability. The most serious consequence of this array of P-value misconceptions is the false belief that the probability of a conclusion being in error can be calculated from the data in a single experiment without reference to external evidence or the plausibility of the underlying mechanism.}
}

@article{Bender2001,
    author = {Bender, R and Lange, S},
    title = {Adjusting for multiple testing--when and how?},
    journal = {J Clin Epidemiol},
    volume = {54},
    number = {4},
    pages = {343--349},
    year = {2001},
    month = {Apr},
    doi = {10.1016/s0895-4356(00)00314-0},
    pmid = {11297884}
}

@article{Kruschke2013,
    author = {Kruschke, J.K.},
    title = {Bayesian estimation supersedes the t test},
    journal = {Journal of Experimental Psychology: General},
    volume = {142},
    number = {2},
    pages = {573--603},
    year = {2013},
    month = {May},
    doi = {10.1037/a0029146},
    note = {Epub 2012 Jul 9},
    pmid = {22774788}
}

@article{MultipleTesting,
    doi = {10.1371/journal.pone.0245824},
    author = {Menyhart, Otília AND Weltz, Boglárka AND Győrffy, Balázs},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {MultipleTesting.com: A tool for life science researchers for multiple hypothesis testing correction},
    year = {2021},
    month = {06},
    volume = {16},
    url = {https://doi.org/10.1371/journal.pone.0245824},
    pages = {1-12},
    abstract = {Scientists from nearly all disciplines face the problem of simultaneously evaluating many hypotheses. Conducting multiple comparisons increases the likelihood that a non-negligible proportion of associations will be false positives, clouding real discoveries. Drawing valid conclusions require taking into account the number of performed statistical tests and adjusting the statistical confidence measures. Several strategies exist to overcome the problem of multiple hypothesis testing. We aim to summarize critical statistical concepts and widely used correction approaches while also draw attention to frequently misinterpreted notions of statistical inference. We provide a step-by-step description of each multiple-testing correction method with clear examples and present an easy-to-follow guide for selecting the most suitable correction technique. To facilitate multiple-testing corrections, we developed a fully automated solution not requiring programming skills or the use of a command line. Our registration free online tool is available at www.multipletesting.com and compiles the five most frequently used adjustment tools, including the Bonferroni, the Holm (step-down), the Hochberg (step-up) corrections, allows to calculate False Discovery Rates (FDR) and q-values. The current summary provides a much needed practical synthesis of basic statistical concepts regarding multiple hypothesis testing in a comprehensible language with well-illustrated examples. The web tool will fill the gap for life science researchers by providing a user-friendly substitute for command-line alternatives.},
    number = {6},

}

@article{VIM,
    title = {Imputation with the {R} Package {VIM}},
    author = {Alexander Kowarik and Matthias Templ},
    journal = {Journal of Statistical Software},
    year = {2016},
    volume = {74},
    number = {7},
    pages = {1--16},
    doi = {10.18637/jss.v074.i07},
  }
  
  @article{visdat,    title = {visdat: Visualising Whole Data Frames},    author = {Nicholas Tierney},    doi = {10.21105/joss.00355},    url = {http://dx.doi.org/10.21105/joss.00355},    year = {2017},    publisher = {Journal of Open Source Software},    volume = {2},    number = {16},    pages = {355},    journal = {JOSS},  }
